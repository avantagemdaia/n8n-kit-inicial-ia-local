
# Kit Inicial de IA Local (Self-Hosted)

O **Kit Inicial de IA Local** Ã© um modelo open-source com Docker Compose, projetado para configurar rapidamente um ambiente de IA e desenvolvimento low-code local.

![n8n.io - Screenshot](https://raw.githubusercontent.com/n8n-io/self-hosted-ai-starter-kit/main/assets/n8n-demo.gif)

Curado por [n8n.io](https://github.com/n8n-io), ele combina a plataforma n8n auto-hospedada com uma lista de ferramentas de IA compatÃ­veis para facilitar a criaÃ§Ã£o de fluxos de trabalho de IA localmente e com seguranÃ§a.

> ğŸ” [Leia o anÃºncio oficial](https://blog.n8n.io/self-hosted-ai/)

## ğŸ”§ O que estÃ¡ incluÃ­do

âœ… [**n8n auto-hospedado**](https://n8n.io/) â€“ Plataforma low-code com mais de 400 integraÃ§Ãµes e componentes de IA avanÃ§ados  
âœ… [**Ollama**](https://ollama.com/) â€“ Plataforma para rodar LLMs localmente  
âœ… [**Qdrant**](https://qdrant.tech/) â€“ Banco vetorial open-source de alta performance  
âœ… [**PostgreSQL**](https://www.postgresql.org/) â€“ Armazena dados com seguranÃ§a em escala

## ğŸ’¡ O que vocÃª pode construir

â­ï¸ **Agentes de IA** para agendamentos  
â­ï¸ **Resumo de PDFs da empresa** com privacidade  
â­ï¸ **Bots inteligentes para Slack**  
â­ï¸ **AnÃ¡lise de documentos financeiros** de forma local e econÃ´mica

## ğŸš€ InstalaÃ§Ã£o

### Clonar o repositÃ³rio

```bash
git clone https://github.com/n8n-io/n8n-kit-inicial-ia-local.git
cd n8n-kit-inicial-ia-local
cp .env.example .env  # Atualize as senhas e chaves
```

### Executando com Docker Compose

#### Para usuÃ¡rios com GPU Nvidia

```bash
docker compose --profile gpu-nvidia up
```

> âš ï¸ Nunca usou sua GPU Nvidia com Docker? Veja [as instruÃ§Ãµes da Ollama](https://github.com/ollama/ollama/blob/main/docs/docker.md)

#### Para usuÃ¡rios com GPU AMD (Linux)

```bash
docker compose --profile gpu-amd up
```

#### Para usuÃ¡rios de Mac (M1 ou superior)

VocÃª pode rodar:
1. Somente via CPU (`docker compose up`)
2. Rodar **Ollama diretamente no Mac** e conectÃ¡-lo ao n8n no Docker.

Edite seu `.env`:
```
OLLAMA_HOST=host.docker.internal:11434
```

No n8n:
- Acesse http://localhost:5678/home/credentials
- Clique em â€œLocal Ollama serviceâ€ e atualize a URL base para:
```
http://host.docker.internal:11434/
```

#### Para outros casos (CPU)

```bash
docker compose --profile cpu up
```

## âš¡ Primeiros passos

1. Acesse http://localhost:5678/ para configurar o n8n.
2. Abra este fluxo: http://localhost:5678/workflow/srOnR8PAY3u4RSwb
3. Clique no botÃ£o **Chat**.
4. Aguarde o download do modelo Llama3.2 no Ollama (verifique o log do Docker).

## ğŸ”— Recursos disponÃ­veis no n8n

- [AI Agent](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.agent/)
- [Classificador de texto](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.text-classifier/)
- [Extrator de informaÃ§Ãµes](https://docs.n8n.io/integrations/builtin/cluster-nodes/root-nodes/n8n-nodes-langchain.information-extractor/)

> ğŸ“ Este kit Ã© ideal para testes e projetos iniciais. Para produÃ§Ã£o, personalize conforme suas necessidades.

## ğŸ”„ AtualizaÃ§Ãµes

### Para Nvidia:
```bash
docker compose --profile gpu-nvidia pull
docker compose create && docker compose --profile gpu-nvidia up
```

### Para Mac:
```bash
docker compose pull
docker compose create && docker compose up
```

### Para CPU:
```bash
docker compose --profile cpu pull
docker compose create && docker compose --profile cpu up
```

## ğŸ“š Leituras recomendadas

- [Agentes de IA na prÃ¡tica com n8n](https://blog.n8n.io/ai-agents/)
- [Tutorial de fluxo de IA](https://docs.n8n.io/advanced-ai/intro-tutorial/)
- [Langchain no n8n](https://docs.n8n.io/advanced-ai/langchain/langchain-n8n/)
- [DiferenÃ§as entre agentes e cadeias](https://docs.n8n.io/advanced-ai/examples/agent-chain-comparison/)
- [O que sÃ£o bancos vetoriais?](https://docs.n8n.io/advanced-ai/examples/understand-vector-databases/)

## ğŸ¥ VÃ­deo tutorial

- [Como instalar IA local com n8n](https://www.youtube.com/)

## ğŸ›ï¸ Templates de IA

Veja ideias em: [Galeria oficial de workflows](https://n8n.io/workflows/categories/ai/)

## ğŸ“ Trabalhando com arquivos locais

O kit cria uma pasta compartilhada (ex: `/data/shared`) que permite ao n8n acessar arquivos do disco.

Use os nodes:
- [Read/Write Files](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.filesreadwrite/)
- [Local File Trigger](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.localfiletrigger/)
- [Execute Command](https://docs.n8n.io/integrations/builtin/core-nodes/n8n-nodes-base.executecommand/)

## ğŸ“œ LicenÃ§a

Licenciado sob [MIT License](LICENSE)

## ğŸ’¬ Suporte

Participe do [FÃ³rum do n8n](https://community.n8n.io/)

- Compartilhe seus fluxos
- Tire dÃºvidas
- Sugira melhorias
